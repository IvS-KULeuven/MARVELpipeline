{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1477b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from database              import DatabaseFromLocalFile\n",
    "from pipeline              import MasterBias, MasterFlat, BiasCorrectedScienceFrames \n",
    "from orderMaskExtraction   import OrderMaskExtraction \n",
    "from orderExtraction       import OrderExtraction\n",
    "from optimalExtraction     import OptimalExtraction\n",
    "from wavelengthCalibration import WavelengthCalibration\n",
    "\n",
    "#%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc51bc",
   "metadata": {},
   "source": [
    "# Database for pipeline\n",
    "\n",
    "All the information of a pipeline components result or input will be stored both in a FITS header as well as in a database. This will make searching and filtering information easier. \n",
    "\n",
    "Instead of running a database we can use a local ascii file as a database proxy. The following code snipet will generate such a database object. \n",
    "\n",
    "For this database object to work properly, it assumes that the local file structure fits what it expects. The observations should be found in the directory: \n",
    "\n",
    "`Data/RawData/CalibrationImages/` for calibration images and,\n",
    "`Data/RawData/ScienceFrames/` for science frames.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78912d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DatabaseFromLocalFile(\"pipelineDatabase.txt\")\n",
    "db.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857fe306",
   "metadata": {},
   "source": [
    "The database can now be inspected by opening the file `pipelineDatabase.txt`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1fe820",
   "metadata": {},
   "source": [
    "# Master Bias Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384ff13",
   "metadata": {},
   "source": [
    "A master bias image takes as input a list of raw bias images. The input can be given as a path name of the files you want to give as input or their hash number. To find the hash number of a raw image you would need to look into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_bias_paths = ['Data/RawData/CalibrationImages/Bias/20221028T164120_BBBBB_H_0000.fits',\n",
    "                  'Data/RawData/CalibrationImages/Bias/20221028T164326_BBBBB_H_0000.fits',\n",
    "                  'Data/RawData/CalibrationImages/Bias/20221028T164524_BBBBB_H_0000.fits',\n",
    "                  'Data/RawData/CalibrationImages/Bias/20221028T164710_BBBBB_H_0000.fits',\n",
    "                  'Data/RawData/CalibrationImages/Bias/20221028T164854_BBBBB_H_0000.fits',\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13581267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master_bias = MasterBias(db, BiasImages=raw_bias_paths)\n",
    "m_bias_values = master_bias.run(\"masterBias.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m_bias_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788132e",
   "metadata": {},
   "source": [
    "This rather boring image is obtained by taking the median image of the images that where given as input. As we can see, it is possible to plot this image in python. However there should also be FITS file in the location `Data/ProcessedData/MasterBias` called `masterBias.fits`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550b182",
   "metadata": {},
   "source": [
    "# Create a Master Flat Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b1e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_flat_paths = ['Data/RawData/CalibrationImages/Flat/20221028T172658_FFFFF_H_0004.fits',\n",
    "                  'Data/RawData/CalibrationImages/Flat/20221028T173510_FFFFF_H_0004.fits',\n",
    "                  'Data/RawData/CalibrationImages/Flat/20221028T174304_FFFFF_H_0004.fits',\n",
    "                  'Data/RawData/CalibrationImages/Flat/20221028T175108_FFFFF_H_0004.fits',\n",
    "                  'Data/RawData/CalibrationImages/Flat/20221028T175908_FFFFF_H_0004.fits',\n",
    "                  'Data/RawData/CalibrationImages/Flat/20221028T180713_FFFFF_H_0004.fits']\n",
    "\n",
    "master_bias_path = \"Data/ProcessedData/MasterBias/masterBias.fits\"\n",
    "masterFlat = MasterFlat(db, FlatImages=raw_flat_paths, BiasImages=master_bias_path)\n",
    "m_Flat_values = masterFlat.run(\"masterFlat.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10769272",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m_Flat_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4180fa36",
   "metadata": {},
   "source": [
    "# Bias corrected Science Image\n",
    "\n",
    "Before a raw science image gets used in the pipeline we correct for the bias by subtracting a Master Bias image from the science image. This is done in the `BiasCorrectedScienceFrames` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_science_paths = [\"Data/RawData/ScienceFrames/20221027T175106_TSSSS_H_0900.fits\", \n",
    "                     \"Data/RawData/ScienceFrames/20221027T175724_TSSSS_H_0900.fits\"]\n",
    "master_bias_path = \"Data/ProcessedData/MasterBias/masterBias.fits\"\n",
    "\n",
    "for raw_science_path in raw_science_paths:\n",
    "    calibration = BiasCorrectedScienceFrames(db, ScienceImages=raw_science_path, BiasImages=master_bias_path)\n",
    "    basename, extension = os.path.splitext(os.path.basename(raw_science_path))\n",
    "    outputPath = basename + \"_BC\" + extension\n",
    "    calibration.run(outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbd90b",
   "metadata": {},
   "source": [
    "# Pixel Mask extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb76cfa",
   "metadata": {},
   "source": [
    "The components up to know did not give a lot of feedback to the user. This is to be expected since they are doing relativly easy things like taking median of images or substracting images. The components that follow are a bit more complicated. Because of this they have an debug option that allows the user to receive feedback from the component while it is running. This behaviour can be toggled by setting the `debug` option to `1, 2 or 3` with `1` being no feedback and `3` the most feedback. If no value is given, the component gives no feedback by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcaa055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a master flat field, determine the pixel masks for each order.  \n",
    "\n",
    "masterflat_path = \"Data/ProcessedData/MasterFlat/masterFlat.fits\"\n",
    "maskExtractor = OrderMaskExtraction(db, debug=3, FlatImages=masterflat_path)\n",
    "x_pixels, y_pixels, flux_values, orders = maskExtractor.run(\"orderMask.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1956c486",
   "metadata": {},
   "source": [
    "The compnent returns the extracted x-pixels, y-pixels, flux for every fiber/order. Once we have this mask (because of the x and y-pixels, we can use this mask to extract the pixels from the science images. The flux values will be used later when we use the optimal extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e5efa8",
   "metadata": {},
   "source": [
    "# Science Order Extraction\n",
    "\n",
    "Now that we have a mask from the flat field, we are able to extract the relavant pixels from the Bias Calibrated Science images. What happens here is pretty straighforward since it simply selects the relevant pixels and saves those together with the mask in a FITS file for every fiber/order. The debug mode here only output an image of the mask overlayed with the science image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the pixel mask, extract the orders of a (bias corrected) science image\n",
    "\n",
    "science_image_paths = [\"Data/ProcessedData/BiasCorrectedScience/20221027T175106_TSSSS_H_0900_BC.fits\", \n",
    "                       \"Data/ProcessedData/BiasCorrectedScience/20221027T175724_TSSSS_H_0900_BC.fits\"]\n",
    "\n",
    "order_mask_path    = \"Data/ProcessedData/ExtractedOrders/orderMask.fits\"\n",
    "for science_image_path in science_image_paths:\n",
    "    orderExtractor = OrderExtraction(db, debug=3, ExtractedOrders=order_mask_path, ScienceImages=science_image_path)\n",
    "    basename, extension = os.path.splitext(os.path.basename(science_image_path))\n",
    "    outputPath = basename[:-3] + \"_EO\" + extension\n",
    "    orderExtractor.run(outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6795ec",
   "metadata": {},
   "source": [
    "Now we have extracted the flux from a Master Flat Field and a Bias Corrected Science image we are able to reduce the 2D spectrum to a 1D spectrum. For this we use the Optimal Order extraction alghoritm as described in [Zachmeister et al.](https://www.aanda.org/articles/aa/full_html/2014/01/aa22746-13/aa22746-13.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e44b1",
   "metadata": {},
   "source": [
    "# Optimal Order Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2d90d",
   "metadata": {},
   "source": [
    "The optimal order extraction routine is quite a heavy computation. It might take a while to run the component. If we use the maximal debug `3`, the output plots 3 images with slider. The first image is a plot of the average flux of a flat field (average in across the orders) for every fiber/order. The order/fibers can be changed by sliding the slidebar in the image. The second plot is the same, but done for a science image. The last plot is the optimal extracted flux (s_x / f_x). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa27731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a 1D spectrum for each order, not yet wavelength calibrated but corrected for\n",
    "# the instrumental response curve. We call this an \"optimal science extraction\".\n",
    "\n",
    "extracted_science_paths = [\"Data/ProcessedData/ExtractedOrders/20221027T175106_TSSSS_H_0900_EO.fits\", \n",
    "                           \"Data/ProcessedData/ExtractedOrders/20221027T175724_TSSSS_H_0900_EO.fits\"]\n",
    "extracted_flat_path = \"Data/ProcessedData/ExtractedOrders/orderMask.fits\"\n",
    "for extracted_science_path in extracted_science_paths:\n",
    "    optimalScience = OptimalExtraction(db, debug=3, ExtractedOrders=[extracted_science_path, extracted_flat_path])\n",
    "    basename, extension = os.path.splitext(os.path.basename(extracted_science_path))\n",
    "    outputPath = basename[:-3] + \"_OP\" + extension\n",
    "    optimalScience.run(outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c81a39",
   "metadata": {},
   "source": [
    "# Wavelength Calibration\n",
    "\n",
    "Finally we are able to run the final (as of this moment) available component of the pipeline: the wavelength calibration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f474895",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_extracted_science_paths = [\"Data/ProcessedData/OptimalExtraction/20221027T175106_TSSSS_H_0900_OP.fits\", \n",
    "                                   \"Data/ProcessedData/OptimalExtraction/20221027T175724_TSSSS_H_0900_OP.fits\"]\n",
    "for optimal_extracted_science_path in optimal_extracted_science_paths:\n",
    "    wavelength_calibration = WavelengthCalibration(db, debug=1, OptimalExtracted=optimal_extracted_science_path)\n",
    "    basename, extension = os.path.splitext(os.path.basename(optimal_extracted_science_path))\n",
    "    outputPath = basename[:-3] + \"_WC\" + extension\n",
    "    wavelength_calibration.run(outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008515e1",
   "metadata": {},
   "source": [
    "Remark that the database object keeps all the information of newly created images into its memory. However once we close this file all this information gets lost and we are no longer able to access it. We are able to save the information to the text. This file can in turn be used again to create a new database object that contains the same information as the one we currently have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5442928b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
