#+TITLE:MARVELpipeline
Data processing and radial velocity estimation pipeline of the MARVEL spectrograph


** Running the different components of the pipeline

The pipeline is made out of different components that can run one after the other.
Every time a component finishes it will create a FITS file with the intermediate results
saved into it. This file can then serve as input for another component. An example of
how these components rely on the results of previous components is illustrated in the following graph:

#+CAPTION:Shows components needed to create an "Optimal Science Extraction" image and how these are in turn dependent on other components.
#+NAME: fig:Optimal Extraction
[[./Docs/Images/my_output_file.png]]



** Running an individual component

*** Initializing a component

For the components to be created we will need (at least) two kinds of input arguments.

The first input argument is the database that will be used. This can be a =DatabaseFromLocalFiles= object 
in which case an ascii file will be used to keep track of all pipeline input/output files, or it can be None, 
in which case MongoDB will be used as a database.

The second argument is a keyword argument Collection=[list of FITS files] where Collection 
is one of the collection names in the left column in the table below. The right-hand column shows what
type of data products they can be given as values. The list of FITS files can be either a list of file paths 
(strings) relative to the base dir of this project, or a list of unique identification hashes (strings).

| Collection       | Files                                                                    |
|------------------+--------------------------------------------------------------------------|
| DarkImages       | Raw Dark Images, Master Dark Images                                      |
| BiasImages       | Raw Bias Images, Master Bias Images                                      |
| Flat Images      | Raw Flat Images, Master Flat Images                                      |
| EtalonImages     | Raw Etalon Images, Calibrated Etalon Images                              |
| ScienceImages    | Raw Science Images, Calibrated Science Images                            |
| ExtractedOrders  | Extracted Etalon Orders, Extracted Science Orders, Extracted Flat Orders |
| OptimalExtracted | Optimal Extracted Science, Optimal Extracted Etalon                      |


In some cases, there is an optional argument that will signify the debug mode when running the component. 
The debug option can be an int ranging from 0 to 3, where 0 means no debug output and 3 means lots of debug output.

We illustrate how to run a component with an example. From the previous image, we can see that in order to obtain 
a *Science Order Extraction* component, we need a *Calibrated Science* and *Order Mask Extraction* as input.

#+begin_src python
  from database        import DatabaseFromLocalFiles
  from orderExtraction import OrderExtraction

  # We run a DatabaseFromLocalFiles object.
  # Since by default such an object only keeps track of raw images, we need to load in a previously generated txt file
  # that also contains a "Calibrated Science Image" and an "Extracted Flat Image".

  db = DatabaseFromLocalFiles("input_file_name.txt")

  # We identify that "Calibrated Science Image" with a hash

  scienceImageHash = "b0ef6a99bde7cdbc968a46fcd7a57e450a554c548d9cc89d7a9555e7236fe05f"

  # and we identify the "Extracted Flat Image" with a path (relative to the MARVELpipeline base dir)

  orderMaskPath = "Data/ProcessedData/ExtractedOrders/orderMask.fits"

  # The component can then be constructed by running

  scienceExtractor = OrderExtraction(db, ExtractedOrders=orderMaskPath, ScienceImages=scienceImageHash, debug=1)
#+end_src

*** Running a component

After having initialized the component, we can run the component by calling the =run()= method.
This method takes an optional argument =outputFileName=. If no argument is given no output file
is saved, otherwise a file with name =outputFileName= is generated as a final product of having
ran the component and the product is added to the database.

#+begin_src python

  # run the component and save the outputfile as extractedScienceTestF.fits

  scienceExtractor1.run("extractedScienceTestF.fits")

  # After having added the "Extracted Science Orders" to the database we want
  # be able to call this file later by saving the new database to an output file

  db.saveToFile("output_file_name.txt")

#+end_src


*** Running the whole pipeline

It is not simple for every component to keep track of the files that are needed to run the component.
The whole pipeline is shown in the following schematic overview of the current implementation.

#+CAPTION:Overview of entire pipeline
#+NAME: fig:whole_pipeline
[[./Docs/Images/whole_pipeline_file.png]]

** Running the pipeline without MongoDB

Normally the pipeline should work in conjunction with a database that keeps track of all the
files and metadata that is generated during the different steps in the pipeline. This is done
either with a MongoDB server (a cross-platform document-oriented NoSQL database program) 
running at the observatory or, if you want to do local tests, with a database based on a local 
ascii file. The latter can be instantiated and used, for example by: 

#+begin_src python
  from database import DatabaseFromLocalFiles

  # Create a DatabaseFromLocalFiles object
  db = DatabaseFromLocalFiles()

  ...

  # After running the pipeline we might want to keep track of the files that were created.
  # This can be done by saving the database into a txt file.

  db.saveToFile("database_object_file.txt")
#+end_src









