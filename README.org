#+TITLE:MARVELpipeline
Data processing and radial velocity estimation pipeline of the MARVEL spectrograph


** Running the different components of the database

The database is made out off different components that can run one after the other.
Every time a component finishes it will create a file with the intemediate results
saved into it. This file can then serve as input for another component. An example of
how these components rely on results of previous components is illustrated in the following graph:

#+BEGIN_SRC dot :file my_output_file.png :cmdline -Kdot -Tpng
  digraph G {
    "Raw Flats" -> "Master Flat";
    "Master Bias" -> "Master Flat";
    "Master Flat" -> "Order Mask Extraction";
    "Order Mask Extraction" -> "Optimal Extraction";
    "Master Dark" -> "Calibrated Science";
    "Master Bias" -> "Calibrated Science";
    "Raw Science" -> "Calibrated Science";
    "Calibrated Science" -> "Science Order Extraction";
    "Order Mask Extraction" -> "Science Order Extraction";
    "Science Order Extraction" -> "Optimal Extraction";
    }
#+END_SRC

#+RESULTS:
[[file:my_output_file.png]]




** Running an individual component

*** Initializing a component

In order for the components to be created we will need (at least) two kinds of inputs.

The first input is the database that will be used. The can be a =DatabaseFromLocalFiles= object or
it can be None, in which case MongoDB will be used as a database.

Secondly, there are the input hashes or the input paths of the fits files that will be used as
input to the component. The are given as keyword arguments (Keywaord=Value), where the keys signify which location in
the database these files can be found (Collection) and the values are either a string with a path (or hash, both work) of
the file or a list of string with paths (or hashes or a mixture of both) to files a mutiple files are needed.
The following table gives an overview of which location in the database (keys of the input) contains which kind of
files.

| Collection       | Files                                                                    |
|------------------+--------------------------------------------------------------------------|
| DarkImages       | Raw Dark Images, Master Dark Images                                      |
| BiasImages       | Raw Bias Images, Master Bias Images                                      |
| Flat Images      | Raw Flat Images, Master Flat Images                                      |
| EtalonImages     | Raw Etalon Images, Calibrated Etalon Images                              |
| ScienceImages    | Raw Science Images, Calibrated Science Images                            |
| ExtractedOrders  | Extracted Etalon Orders, Extracted Science Orders, Extracted Flat Orders |
| OptimalExtracted | Optimal Extracted Science, Optimal Extracted Etalon                      |



In some cases, there is an optinal argument that will signifies the debug
mode when running the component. The debug option can be an int ranging from 0 to 3, where 0 means no debug output
and 3 means lots of debug output.

We illustrated how to run a component with an example. From
the previous image, we can see that in order to obtain a *Science Order Extraction* component, we
need a *Calibrated Science* and *Order Mask Extraction* as input.

#+begin_src python
  from database        import DatabaseFromLocalFiles
  from orderExtraction import OrderExtraction

  # We run a DatabaseFromLocalFiles object.
  # Since by default such a object only keeps track of raw images, we need to load in a previously generated txt file
  # that also contains a "Calibrated Science Image" and a "Extracted Flat Image".

  db = DatabaseFromLocalFiles("input_file_name.txt")

  # We identify that "Calibrated Science Image" with a hash
  scienceImageHash = "b0ef6a99bde7cdbc968a46fcd7a57e450a554c548d9cc89d7a9555e7236fe05f"

  # and we identify the "Extracted Flat Image" with a path (relative to MARVELpipeline)
  orderMaskPath = "Data/ProcessedData/ExtractedOrders/orderMask.fits"

  # The component can then be constructed by running

  scienceExtractor = OrderExtraction(db, debug=1, ExtractedOrders=orderMaskPath,
					  ScienceImages=scienceImageHash)
#+end_src

*** Running a component

After having initialized the component, we can run the component by calling the =run()= method.
This method takes an optional argument =outputFileName=. If no argument is given no output file
is saved, otherwise a file with name =outputFileName= is generated as final product of having
ran the component and the object is added to the database.

#+begin_src python

  # run the component and save the outputfile as extractedScienceTestF.fits
  scienceExtractor1.run("extractedScienceTestF.fits")

  # After having added the "Extracted Science Orders" to the database we want
  # be able to call this file later by saving the new database to an output file
  db.saveToFile("input_file_name.txt")


#+end_src



** Running the pipeline without MongoDB

Normally the pipeline should work in conjunction with a database that keeps track of all the
files and metadata that get generated during the different steps in the pipeline. For local
users, it is possible to use the software without needing to install the database. This can be
done by using a =DatabaseFromLocalFiles= object. This object is set up by using the local files
that are present in =/Data/RawData/=. It mimics the behaviour of a database in that it keeps track
of files that are created while running the database. After

*** Creating a =DatabaseFromLocalFiles= object

When running the pipeline for the first time while using a =DatabaseFromLocalFiles= object, the
=DatabaseFromLocalFiles= object gets createad by running

#+begin_src python
  from database import DatabaseFromLocalFiles

  # Create a DatabaseFromLocalFiles object
  db = DatabaseFromLocalFiles()

  ...

  # After running the pipeline we might want to keep track of the files that were created.
  # This can be done by saving the database into a txt file.

  db.saveToFile("database_object_file.txt")
#+end_src

If at a later date we want to continue using this database we can simply create a =DatabaseFromLocalFiles=
object with as an argument the path to our txt file.

#+begin_src python
  db = DatabaseFromLocalFiles("database_object_file.txt")
#+end_src







